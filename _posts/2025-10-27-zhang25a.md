---
title: Cloud Resource Auto-Scaling Strategy Based on CNN-Lightweight Transformer
abstract: "  With the rapid development of cloud computing and containerization technologies,
  load forecasting has become increasingly important in resource management. This
  paper proposes a load forecasting model based on a lightweight Transformer and local
  convolution fusion, aiming to efficiently capture multi-scale features of complex
  loads while maintaining low computational overhead. Furthermore, this paper introduces
  a predictive error feedback and adaptive cooling period adjustment mechanism based
  on traditional Horizontal Pod Autoscaling (HPA), enhancing the systemâ€™s adaptability
  to load variations by dynamically adjusting scaling strategies. Experimental results
  demonstrate that the proposed model excels in both load forecasting accuracy and
  scheduling stability, effectively balancing response speed and system robustness,
  providing an efficient solution for cloud resource management."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang25a
month: 0
tex_title: Cloud Resource Auto-Scaling Strategy Based on CNN-Lightweight Transformer
firstpage: 30
lastpage: 35
page: 30-35
order: 30
cycles: false
bibtex_author: Zhang, Yue and Song, Chunhe
author:
- given: Yue
  family: Zhang
- given: Chunhe
  family: Song
date: 2025-10-27
address:
container-title: Proceedings of 2025 2nd International Conference on Machine Learning
  and Intelligent Computing
volume: '278'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 27
pdf: https://raw.githubusercontent.com/mlresearch/v278/main/assets/zhang25a/zhang25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
