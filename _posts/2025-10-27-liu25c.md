---
title: 'PatchPrune: Reducing Hallucinations in Vision Language Models by Pruning Redundant
  Image Patches'
abstract: 'Large language models (LLMs) have advanced significantly in natural language
  processing, and vision language models (VLMs) have extended this progress to tasks
  like image captioning and visual question answering (VQA). Despite this success,
  VLMs often generate hallucinated or factually inconsistent contents. Traditional
  methods focus on improving model reasoning by modifying the inference procedure,
  but we propose a new approach: PatchPrune, which dynamically prunes redundant or
  uninformative image patches, using a composite importance score based on activation
  magnitude and feature entropy. As shown in Figure  By reducing input noise, PatchPrune
  enables the model to focus on relevant features, improving the accuracy and reliability
  of its outputs. Experimental results show that PatchPrune enhances multimodal reasoning
  and mitigates hallucinations effectively.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu25c
month: 0
tex_title: 'PatchPrune: Reducing Hallucinations in Vision Language Models by Pruning
  Redundant Image Patches'
firstpage: 298
lastpage: 304
page: 298-304
order: 298
cycles: false
bibtex_author: Liu, Changyan
author:
- given: Changyan
  family: Liu
date: 2025-10-27
address:
container-title: Proceedings of 2025 2nd International Conference on Machine Learning
  and Intelligent Computing
volume: '278'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 27
pdf: https://raw.githubusercontent.com/mlresearch/v278/main/assets/liu25c/liu25c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
